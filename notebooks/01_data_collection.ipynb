{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Data Collection\n",
    "\n",
    "This notebook downloads and saves **all raw data sources** needed for the TSLA direction prediction project.\n",
    "\n",
    "| # | Source | Method |\n",
    "|---|--------|--------|\n",
    "| 1 | TSLA daily OHLCV | `yfinance` |\n",
    "| 2 | Technical indicators | `pandas_ta` |\n",
    "| 3 | Elon Musk tweets | Kaggle CSV (manual download) |\n",
    "| 4 | Google Trends | `pytrends` |\n",
    "| 5 | Fundamentals (revenue, EPS) | `yfinance` |"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:02:56.701482Z",
     "iopub.status.busy": "2026-02-17T16:02:56.701351Z",
     "iopub.status.idle": "2026-02-17T16:02:58.228060Z",
     "shell.execute_reply": "2026-02-17T16:02:58.227686Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:43.880720Z",
     "start_time": "2026-02-19T15:07:42.831743Z"
    }
   },
   "source": "import sys, os\nsys.path.insert(0, os.path.abspath('..'))\n\nimport pandas as pd\nimport numpy as np\nimport yfinance as yf\nimport pandas_ta as ta\nfrom pytrends.request import TrendReq\nfrom src.helpers import DATA_RAW, DATA_PROCESSED, DATA_EXTERNAL, create_target\nimport time, warnings\nwarnings.filterwarnings('ignore')",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TSLA Historical OHLCV Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:02:58.229389Z",
     "iopub.status.busy": "2026-02-17T16:02:58.229281Z",
     "iopub.status.idle": "2026-02-17T16:03:01.838253Z",
     "shell.execute_reply": "2026-02-17T16:03:01.837909Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:44.801530Z",
     "start_time": "2026-02-19T15:07:44.365699Z"
    }
   },
   "source": [
    "tsla = yf.download('TSLA', start='2010-01-01', auto_adjust=False)\n",
    "\n",
    "# Flatten multi-level columns if present\n",
    "if isinstance(tsla.columns, pd.MultiIndex):\n",
    "    tsla.columns = tsla.columns.get_level_values(0)\n",
    "\n",
    "tsla.index = pd.to_datetime(tsla.index).tz_localize(None)\n",
    "tsla.index.name = 'Date'\n",
    "\n",
    "# Drop Adj Close (identical to Close with auto_adjust=False after splits)\n",
    "if 'Adj Close' in tsla.columns:\n",
    "    tsla.drop(columns=['Adj Close'], inplace=True)\n",
    "\n",
    "print(f\"Shape: {tsla.shape}\")\n",
    "print(f\"Date range: {tsla.index.min()} → {tsla.index.max()}\")\n",
    "print(f\"Columns: {list(tsla.columns)}\")\n",
    "print(f\"\\nSanity checks:\")\n",
    "print(f\"  Any missing Close? {tsla['Close'].isna().sum()}\")\n",
    "print(f\"  Any missing Volume? {tsla['Volume'].isna().sum()}\")\n",
    "print(f\"  Any zero Volume? {(tsla['Volume'] == 0).sum()}\")\n",
    "print(f\"  Frequency: daily trading days (no weekends/holidays)\")\n",
    "tsla.tail()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3935, 5)\n",
      "Date range: 2010-06-29 00:00:00 → 2026-02-19 00:00:00\n",
      "Columns: ['Close', 'High', 'Low', 'Open', 'Volume']\n",
      "\n",
      "Sanity checks:\n",
      "  Any missing Close? 0\n",
      "  Any missing Volume? 0\n",
      "  Any zero Volume? 0\n",
      "  Frequency: daily trading days (no weekends/holidays)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Price            Close        High         Low        Open    Volume\n",
       "Date                                                                \n",
       "2026-02-12  417.070007  436.230011  414.000000  430.299988  61933400\n",
       "2026-02-13  417.440002  424.059998  410.880005  414.309998  51434100\n",
       "2026-02-17  410.630005  413.720001  400.510010  412.359985  59678800\n",
       "2026-02-18  411.320007  416.899994  409.579987  411.109985  45831600\n",
       "2026-02-19  409.349915  410.299988  404.109985  407.333496   9269167"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-02-12</th>\n",
       "      <td>417.070007</td>\n",
       "      <td>436.230011</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>430.299988</td>\n",
       "      <td>61933400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-13</th>\n",
       "      <td>417.440002</td>\n",
       "      <td>424.059998</td>\n",
       "      <td>410.880005</td>\n",
       "      <td>414.309998</td>\n",
       "      <td>51434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-17</th>\n",
       "      <td>410.630005</td>\n",
       "      <td>413.720001</td>\n",
       "      <td>400.510010</td>\n",
       "      <td>412.359985</td>\n",
       "      <td>59678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-18</th>\n",
       "      <td>411.320007</td>\n",
       "      <td>416.899994</td>\n",
       "      <td>409.579987</td>\n",
       "      <td>411.109985</td>\n",
       "      <td>45831600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-19</th>\n",
       "      <td>409.349915</td>\n",
       "      <td>410.299988</td>\n",
       "      <td>404.109985</td>\n",
       "      <td>407.333496</td>\n",
       "      <td>9269167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:01.848824Z",
     "iopub.status.busy": "2026-02-17T16:03:01.848722Z",
     "iopub.status.idle": "2026-02-17T16:03:01.862992Z",
     "shell.execute_reply": "2026-02-17T16:03:01.862596Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:51.572151Z",
     "start_time": "2026-02-19T15:07:51.549001Z"
    }
   },
   "source": [
    "# Create target variable: 1 if next day's close > today's close\n",
    "tsla['target'] = create_target(tsla)\n",
    "\n",
    "print(f\"Target distribution:\\n{tsla['target'].value_counts(normalize=True).round(3)}\")\n",
    "tsla.to_csv(DATA_RAW / 'tsla_ohlcv.csv')\n",
    "print(f\"Saved to {DATA_RAW / 'tsla_ohlcv.csv'}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "target\n",
      "1    0.516\n",
      "0    0.484\n",
      "Name: proportion, dtype: float64\n",
      "Saved to /Users/matheomenges/Desktop/tsla-direction-predictor/data/raw/tsla_ohlcv.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:01.864001Z",
     "iopub.status.busy": "2026-02-17T16:03:01.863938Z",
     "iopub.status.idle": "2026-02-17T16:03:02.053385Z",
     "shell.execute_reply": "2026-02-17T16:03:02.053043Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:52.950704Z",
     "start_time": "2026-02-19T15:07:52.806792Z"
    }
   },
   "source": [
    "df_ta = tsla[['Open', 'High', 'Low', 'Close', 'Volume', 'target']].copy()\n",
    "\n",
    "# --- Moving Averages ---\n",
    "df_ta.ta.sma(length=5, append=True)\n",
    "df_ta.ta.sma(length=10, append=True)\n",
    "df_ta.ta.sma(length=20, append=True)\n",
    "df_ta.ta.sma(length=50, append=True)\n",
    "df_ta.ta.ema(length=12, append=True)\n",
    "df_ta.ta.ema(length=26, append=True)\n",
    "\n",
    "# --- RSI ---\n",
    "df_ta.ta.rsi(length=14, append=True)\n",
    "\n",
    "# --- MACD ---\n",
    "df_ta.ta.macd(append=True)\n",
    "\n",
    "# --- Bollinger Bands ---\n",
    "df_ta.ta.bbands(length=20, append=True)\n",
    "\n",
    "# --- ATR (Average True Range) ---\n",
    "df_ta.ta.atr(length=14, append=True)\n",
    "\n",
    "# --- Stochastic Oscillator ---\n",
    "df_ta.ta.stoch(append=True)\n",
    "\n",
    "# --- OBV (On-Balance Volume) ---\n",
    "df_ta.ta.obv(append=True)\n",
    "\n",
    "# --- Historical Volatility (20-day rolling std of returns) ---\n",
    "df_ta['volatility_20'] = df_ta['Close'].pct_change().rolling(20).std()\n",
    "\n",
    "print(f\"Shape with indicators: {df_ta.shape}\")\n",
    "print(f\"New columns: {[c for c in df_ta.columns if c not in tsla.columns]}\")\n",
    "df_ta.to_csv(DATA_RAW / 'tsla_with_ta.csv')\n",
    "print(\"Saved.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape with indicators: (3935, 27)\n",
      "New columns: ['SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'EMA_12', 'EMA_26', 'RSI_14', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'ATRr_14', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHh_14_3_3', 'OBV', 'volatility_20']\n",
      "Saved.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Elon Musk Tweets\n\n**Manual step:** Download a tweets dataset from Kaggle and place it in `data/external/`.\n\nRecommended datasets (search Kaggle for the most recent):\n- *Elon Musk Tweets (2010-2024+)* — look for the largest/most recent one\n- Filename assumption: `elonmusk_tweets.csv`\n\nThe cell below loads the CSV, removes replies and retweets, and computes a **daily word score** using log-odds differential words — terms statistically overrepresented on days before TSLA up or down moves.  \nWe use ALL original tweets (not just Tesla-related) — Elon IS Tesla, and his non-Tesla tweets (politics, SpaceX, rants) also predict TSLA direction."
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.054545Z",
     "iopub.status.busy": "2026-02-17T16:03:02.054476Z",
     "iopub.status.idle": "2026-02-17T16:03:02.382464Z",
     "shell.execute_reply": "2026-02-17T16:03:02.382142Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:55.451035Z",
     "start_time": "2026-02-19T15:07:55.105301Z"
    }
   },
   "source": [
    "TWEETS_PATH = DATA_EXTERNAL / 'elonmusk_tweets.csv'\n",
    "\n",
    "if TWEETS_PATH.exists():\n",
    "    tweets_raw = pd.read_csv(TWEETS_PATH, parse_dates=True)\n",
    "    print(f\"Loaded {len(tweets_raw)} tweets.\")\n",
    "    print(f\"Columns: {list(tweets_raw.columns)}\")\n",
    "    tweets_raw.head()\n",
    "else:\n",
    "    print(f\"⚠ File not found at {TWEETS_PATH}\")\n",
    "    print(\"Please download a Kaggle tweets dataset and place the CSV there.\")\n",
    "    tweets_raw = None"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55099 tweets.\n",
      "Columns: ['id', 'url', 'twitterUrl', 'fullText', 'retweetCount', 'replyCount', 'likeCount', 'quoteCount', 'viewCount', 'createdAt', 'bookmarkCount', 'isReply', 'inReplyToId', 'conversationId', 'inReplyToUserId', 'inReplyToUsername', 'isPinned', 'isRetweet', 'isQuote', 'isConversationControlled', 'possiblySensitive', 'quoteId', 'quote', 'retweet']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.383587Z",
     "iopub.status.busy": "2026-02-17T16:03:02.383519Z",
     "iopub.status.idle": "2026-02-17T16:03:02.539806Z",
     "shell.execute_reply": "2026-02-17T16:03:02.539406Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:07:57.273122Z",
     "start_time": "2026-02-19T15:07:57.137767Z"
    }
   },
   "source": "import re\n\n# Processing pipeline for raw tweet CSV:\n#   Step 1 — Detect date/text columns and drop replies & retweets, keeping only original tweets\n#   Step 2 — Clean text (strip URLs, mentions, punctuation) and tokenize with a domain stop-word list\n#   Step 3 — Score each tweet using bullish/bearish word sets derived from log-odds ratio analysis\n#   Step 4 — Aggregate to daily level: tweet count, word scores, and Tesla-keyword flag\n\nif tweets_raw is not None:\n    # Detect the date column\n    date_col = None\n    for candidate in ['createdAt', 'date', 'created_at', 'datetime', 'timestamp', 'Date']:\n        if candidate in tweets_raw.columns:\n            date_col = candidate\n            break\n    \n    # Detect the text column\n    text_col = None\n    for candidate in ['fullText', 'text', 'tweet', 'content', 'Tweet', 'Text']:\n        if candidate in tweets_raw.columns:\n            text_col = candidate\n            break\n    \n    print(f\"Using date_col='{date_col}', text_col='{text_col}'\")\n    \n    # Keep metadata columns\n    keep_cols = [date_col, text_col]\n    for meta in ['isReply', 'isRetweet', 'isQuote', 'likeCount', 'retweetCount', 'viewCount']:\n        if meta in tweets_raw.columns:\n            keep_cols.append(meta)\n    \n    tweets = tweets_raw[keep_cols].copy()\n    tweets = tweets.rename(columns={date_col: 'date', text_col: 'text'})\n    tweets['date'] = pd.to_datetime(tweets['date'], utc=True, errors='coerce')\n    tweets = tweets.dropna(subset=['date', 'text'])\n    tweets['date'] = tweets['date'].dt.tz_localize(None).dt.normalize()\n    \n    # ── STEP 1: Remove replies and retweets ──\n    n_before = len(tweets)\n    for col in ['isReply', 'isRetweet']:\n        if col in tweets.columns:\n            tweets[col] = tweets[col].astype(str).str.lower().isin(['true', '1'])\n    \n    is_reply = tweets.get('isReply', pd.Series(False, index=tweets.index))\n    is_retweet = tweets.get('isRetweet', pd.Series(False, index=tweets.index))\n    tweets = tweets[~is_reply & ~is_retweet]\n    \n    print(f\"\\nTweet type filtering:\")\n    print(f\"  Total tweets: {n_before}\")\n    print(f\"  Replies removed: {is_reply.sum()} ({is_reply.sum()/n_before*100:.1f}%)\")\n    print(f\"  Retweets removed: {is_retweet.sum()} ({is_retweet.sum()/n_before*100:.1f}%)\")\n    print(f\"  Kept (originals): {len(tweets)} ({len(tweets)/n_before*100:.1f}%)\")\n    \n    # ── STEP 2: Clean text and tokenize ──\n    def clean_text(text):\n        text = re.sub(r'http\\S+', '', str(text))\n        text = re.sub(r'@\\w+', '', text)\n        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n        return text.lower().strip()\n    \n    STOP = set(\"\"\"\n    i me my myself we our ours ourselves you your yours yourself yourselves he him his himself\n    she her hers herself it its itself they them their theirs themselves what which who whom this\n    that these those am is are was were be been being have has had having do does did doing a an\n    the and but if or because as until while of at by for with about against between through during\n    before after above below to from up down in out on off over under again further then once here\n    there when where why how all both each few more most other some such no nor not only own same\n    so than too very s t can will just don should now d ll m o re ve y ain aren couldn didn doesn\n    hadn hasn haven isn ma mightn mustn needn shan shouldn wasn weren won wouldn\n    also gonna gotta wanna lol yes yeah yep nah true false really actually basically literally\n    just like even still well thing things way much many lot lots got get gets going come\n    good great best better make makes made right now new already one two three first last next\n    back amp https www http co rt thats dont didnt doesnt isnt wasnt wont cant wouldnt couldnt\n    youre theyre weve ive hes shes per would could let say said says every need know think\n    something anything everything want year years day days time times people take use used\n    using im theres heres whats thats gonna need something tell look see goes went doing\n    been getting big long high since around tesla teslas elon musk elonmusk\n    \"\"\".split())\n    \n    def tokenize(text):\n        return [w for w in text.split() if len(w) > 2 and w not in STOP and not w.isdigit()]\n    \n    tweets['clean'] = tweets['text'].apply(clean_text)\n    tweets['tokens'] = tweets['clean'].apply(tokenize)\n    \n    # ── STEP 3: Word score using log-odds differential words ──\n    # These word sets were discovered via log-odds ratio analysis on ALL 14.9k originals\n    # Bullish words: overrepresented before TSLA up days (Fisher p < 0.10)\n    BULLISH_WORDS = {'air', 'complex', 'details', 'feel', 'highest', 'often', 'sometimes', 'spend'}\n    # Bearish words: overrepresented before TSLA down days (Fisher p < 0.10)\n    BEARISH_WORDS = {\n        'accounts', 'add', 'administration', 'algorithm', 'almost', 'america', 'amount',\n        'app', 'away', 'bankrupt', 'biggest', 'bit', 'btw', 'bureaucracy', 'california',\n        'call', 'correct', 'crime', 'critical', 'dei', 'dem', 'due', 'electric', 'factory',\n        'fast', 'fight', 'fired', 'free', 'government', 'greater', 'happening', 'immediately',\n        'improvements', 'increase', 'incredible', 'join', 'law', 'left', 'massive', 'means',\n        'meant', 'mind', 'needed', 'nice', 'numbers', 'pennsylvania', 'permanent', 'possible',\n        'president', 'press', 'public', 'reach', 'reminder', 'risk', 'seem', 'ship', 'size',\n        'smart', 'spending', 'state', 'stop', 'support', 'took', 'trying', 'twitter', 'voice',\n        'voters', 'votes', 'within'\n    }\n    \n    tweets['bull_count'] = tweets['tokens'].apply(lambda t: len(set(t) & BULLISH_WORDS))\n    tweets['bear_count'] = tweets['tokens'].apply(lambda t: len(set(t) & BEARISH_WORDS))\n    tweets['word_score'] = tweets['bull_count'] - tweets['bear_count']\n    \n    # ── STEP 4: Daily aggregation ──\n    tweets_daily = tweets.groupby('date').agg(\n        tweet_count=('text', 'count'),\n        tweet_bull_count=('bull_count', 'sum'),\n        tweet_bear_count=('bear_count', 'sum'),\n        tweet_word_score=('word_score', 'sum'),\n    )\n    tweets_daily.index = pd.to_datetime(tweets_daily.index)\n    \n    # Also flag Tesla-specific tweet days\n    TESLA_KEYWORDS = ['tesla', 'tsla', 'fsd', 'cybertruck', 'robotaxi',\n                      'deliveries', 'model y', 'model 3', 'model s', 'model x',\n                      'autopilot', 'gigafactory', 'supercharger', 'megapack',\n                      'powerwall', 'full self driving', 'self driving']\n    text_lower = tweets['text'].str.lower()\n    tesla_mask = pd.Series(False, index=tweets.index)\n    for kw in TESLA_KEYWORDS:\n        tesla_mask |= text_lower.str.contains(kw, na=False)\n    \n    tesla_daily = tweets[tesla_mask].groupby('date').agg(\n        tesla_tweet_count=('text', 'count'),\n    )\n    tweets_daily = tweets_daily.join(tesla_daily, how='left')\n    tweets_daily['tesla_tweet_count'] = tweets_daily['tesla_tweet_count'].fillna(0).astype(int)\n    tweets_daily['has_tesla_tweet'] = (tweets_daily['tesla_tweet_count'] > 0).astype(int)\n    \n    print(f\"\\nDaily aggregated shape: {tweets_daily.shape}\")\n    print(f\"Days with any tweet: {len(tweets_daily)}\")\n    print(f\"Days with Tesla tweet: {int(tweets_daily['has_tesla_tweet'].sum())}\")\n    print(f\"\\nWord score stats:\")\n    print(tweets_daily['tweet_word_score'].describe().round(2))\n    print(f\"\\nColumns: {list(tweets_daily.columns)}\")\n    \n    tweets_daily.to_csv(DATA_RAW / 'elon_tweets_daily.csv')\n    print(f\"\\nSaved to {DATA_RAW / 'elon_tweets_daily.csv'}\")\n    tweets_daily.tail()\nelse:\n    print(\"Skipping tweet processing — no data loaded.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using date_col='createdAt', text_col='fullText'\n",
      "\n",
      "Tweet type filtering:\n",
      "  Total tweets: 55099\n",
      "  Replies removed: 39096 (71.0%)\n",
      "  Retweets removed: 1092 (2.0%)\n",
      "  Kept (originals): 14911 (27.1%)\n",
      "\n",
      "Daily aggregated shape: (2911, 6)\n",
      "Days with any tweet: 2911\n",
      "Days with Tesla tweet: 950\n",
      "\n",
      "Word score stats:\n",
      "count    2911.0\n",
      "mean       -1.3\n",
      "std         3.2\n",
      "min       -43.0\n",
      "25%        -1.0\n",
      "50%         0.0\n",
      "75%         0.0\n",
      "max         2.0\n",
      "Name: tweet_word_score, dtype: float64\n",
      "\n",
      "Columns: ['tweet_count', 'tweet_bull_count', 'tweet_bear_count', 'tweet_word_score', 'tesla_tweet_count', 'has_tesla_tweet']\n",
      "\n",
      "Saved to /Users/matheomenges/Desktop/tsla-direction-predictor/data/raw/elon_tweets_daily.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google Trends (Categorized, Weekly)\n",
    "\n",
    "We use pre-collected weekly Google Trends data with **actionable, categorized** search terms:\n",
    "\n",
    "| Category | Terms | Signal |\n",
    "|----------|-------|--------|\n",
    "| **risk** | tesla recall, crash, lawsuit, investigation | Spikes during negative events |\n",
    "| **investor** | buy/sell tesla stock, tsla earnings, stock price | Active trading interest |\n",
    "| **product** | tesla fsd, robotaxi, cybertruck delivery, model 2 | Product catalyst attention |\n",
    "| **brand** | Tesla (baseline) | Overall brand awareness |\n",
    "\n",
    "Each category is collected separately so niche terms aren't crushed to 0 by the dominant \"Tesla\" baseline.\n",
    "Overlapping 5-year windows give **weekly** granularity (vs monthly for generic pytrends queries)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.540864Z",
     "iopub.status.busy": "2026-02-17T16:03:02.540803Z",
     "iopub.status.idle": "2026-02-17T16:03:02.545532Z",
     "shell.execute_reply": "2026-02-17T16:03:02.545214Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:08:01.633950Z",
     "start_time": "2026-02-19T15:08:01.621274Z"
    }
   },
   "source": [
    "# Load pre-collected granular Google Trends data\n",
    "# (collected by data/google_trends_collection.py with categorized search terms)\n",
    "GTRENDS_PATH = DATA_RAW / 'google_trends_granular.csv'\n",
    "\n",
    "if GTRENDS_PATH.exists():\n",
    "    gtrends = pd.read_csv(GTRENDS_PATH, index_col='Date', parse_dates=True)\n",
    "    gtrends.index = gtrends.index.tz_localize(None)\n",
    "    print(f\"Google Trends shape: {gtrends.shape}\")\n",
    "    print(f\"Date range: {gtrends.index.min().date()} → {gtrends.index.max().date()}\")\n",
    "    print(f\"Granularity: weekly ({len(gtrends)} data points)\")\n",
    "    print(f\"\\nColumns by category:\")\n",
    "    for cat in ['tesla', 'risk', 'investor', 'product']:\n",
    "        cols = [c for c in gtrends.columns if f'gtrend_{cat}' in c]\n",
    "        if cols:\n",
    "            print(f\"  {cat}: {cols}\")\n",
    "    print(f\"\\nSample (last 3 rows):\")\n",
    "    print(gtrends.tail(3).to_string())\n",
    "else:\n",
    "    print(f\"⚠ Google Trends file not found at {GTRENDS_PATH}\")\n",
    "    print(\"Run: python data/google_trends_collection.py\")\n",
    "    gtrends = None"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Trends shape: (328, 13)\n",
      "Date range: 2016-01-01 → 2026-02-15\n",
      "Granularity: weekly (328 data points)\n",
      "\n",
      "Columns by category:\n",
      "  tesla: ['gtrend_tesla']\n",
      "  risk: ['gtrend_risk_tesla_recall', 'gtrend_risk_tesla_crash', 'gtrend_risk_tesla_lawsuit', 'gtrend_risk_tesla_investigation']\n",
      "  investor: ['gtrend_investor_buy_tesla_stock', 'gtrend_investor_sell_tesla_stock', 'gtrend_investor_tsla_earnings', 'gtrend_investor_tesla_stock_price']\n",
      "  product: ['gtrend_product_tesla_fsd', 'gtrend_product_tesla_robotaxi', 'gtrend_product_cybertruck_delivery', 'gtrend_product_tesla_model_2']\n",
      "\n",
      "Sample (last 3 rows):\n",
      "            gtrend_tesla  gtrend_risk_tesla_recall  gtrend_risk_tesla_crash  gtrend_risk_tesla_lawsuit  gtrend_risk_tesla_investigation  gtrend_investor_buy_tesla_stock  gtrend_investor_sell_tesla_stock  gtrend_investor_tsla_earnings  gtrend_investor_tesla_stock_price  gtrend_product_tesla_fsd  gtrend_product_tesla_robotaxi  gtrend_product_cybertruck_delivery  gtrend_product_tesla_model_2\n",
      "Date                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      "2026-02-01          39.0                       2.0                      6.0                        3.0                              2.0                              1.0                               0.0                            1.0                               23.0                      19.0                            4.0                                 0.0                          14.0\n",
      "2026-02-08          35.0                       1.0                      3.0                        1.0                              1.0                              1.0                               0.0                            0.0                               15.0                      16.0                            2.0                                 0.0                           8.0\n",
      "2026-02-15          34.0                       1.0                      3.0                        1.0                              1.0                              0.0                               0.0                            0.0                                7.0                      17.0                            3.0                                 0.0                           8.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fundamentals (Quarterly Revenue & EPS)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.546566Z",
     "iopub.status.busy": "2026-02-17T16:03:02.546501Z",
     "iopub.status.idle": "2026-02-17T16:03:02.552687Z",
     "shell.execute_reply": "2026-02-17T16:03:02.552263Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:08:03.835660Z",
     "start_time": "2026-02-19T15:08:03.825153Z"
    }
   },
   "source": [
    "# Load comprehensive fundamentals from curated CSV (SEC filings data, 2012-2025)\n",
    "# yfinance only returns ~5 recent quarters, so we use a manually compiled dataset\n",
    "\n",
    "FUND_PATH = DATA_EXTERNAL / 'tsla_quarterly_fundamentals.csv'\n",
    "fundamentals = pd.read_csv(FUND_PATH, parse_dates=['quarter_end'], index_col='quarter_end')\n",
    "fundamentals.index.name = 'Date'\n",
    "\n",
    "# Add derived features\n",
    "fundamentals['revenue_growth_qoq'] = fundamentals['quarterly_revenue'].pct_change()\n",
    "fundamentals['eps_growth_qoq'] = fundamentals['eps_diluted'].diff()\n",
    "fundamentals['profit_margin'] = fundamentals['net_income'] / fundamentals['quarterly_revenue']\n",
    "\n",
    "print(f\"Fundamentals: {fundamentals.shape[0]} quarters ({fundamentals.index.min().date()} → {fundamentals.index.max().date()})\")\n",
    "print(f\"Columns: {list(fundamentals.columns)}\")\n",
    "print(f\"\\nMissing values:\\n{fundamentals.isna().sum()}\")\n",
    "\n",
    "fundamentals.to_csv(DATA_RAW / 'tsla_fundamentals.csv')\n",
    "print(f\"\\nSaved to {DATA_RAW / 'tsla_fundamentals.csv'}\")\n",
    "fundamentals.tail(10)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundamentals: 56 quarters (2012-03-31 → 2025-12-31)\n",
      "Columns: ['quarterly_revenue', 'eps_diluted', 'net_income', 'revenue_growth_qoq', 'eps_growth_qoq', 'profit_margin']\n",
      "\n",
      "Missing values:\n",
      "quarterly_revenue     0\n",
      "eps_diluted           0\n",
      "net_income            0\n",
      "revenue_growth_qoq    1\n",
      "eps_growth_qoq        1\n",
      "profit_margin         0\n",
      "dtype: int64\n",
      "\n",
      "Saved to /Users/matheomenges/Desktop/tsla-direction-predictor/data/raw/tsla_fundamentals.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            quarterly_revenue  eps_diluted  net_income  revenue_growth_qoq  \\\n",
       "Date                                                                         \n",
       "2023-09-30        23350000000         0.53  1853000000           -0.063265   \n",
       "2023-12-31        25167000000         2.27  7928000000            0.077816   \n",
       "2024-03-31        21301000000         0.41  1129000000           -0.153614   \n",
       "2024-06-30        25500000000         0.40  1478000000            0.197127   \n",
       "2024-09-30        25182000000         0.62  2167000000           -0.012471   \n",
       "2024-12-31        25707000000         0.61  2314000000            0.020848   \n",
       "2025-03-31        19335000000         0.12   409000000           -0.247870   \n",
       "2025-06-30        22496000000         0.33  1134000000            0.163486   \n",
       "2025-09-30        28095000000         0.39  1853000000            0.248889   \n",
       "2025-12-31        24901000000         0.24  1076000000           -0.113686   \n",
       "\n",
       "            eps_growth_qoq  profit_margin  \n",
       "Date                                       \n",
       "2023-09-30           -0.25       0.079358  \n",
       "2023-12-31            1.74       0.315016  \n",
       "2024-03-31           -1.86       0.053002  \n",
       "2024-06-30           -0.01       0.057961  \n",
       "2024-09-30            0.22       0.086054  \n",
       "2024-12-31           -0.01       0.090014  \n",
       "2025-03-31           -0.49       0.021153  \n",
       "2025-06-30            0.21       0.050409  \n",
       "2025-09-30            0.06       0.065955  \n",
       "2025-12-31           -0.15       0.043211  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarterly_revenue</th>\n",
       "      <th>eps_diluted</th>\n",
       "      <th>net_income</th>\n",
       "      <th>revenue_growth_qoq</th>\n",
       "      <th>eps_growth_qoq</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-09-30</th>\n",
       "      <td>23350000000</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1853000000</td>\n",
       "      <td>-0.063265</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.079358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>25167000000</td>\n",
       "      <td>2.27</td>\n",
       "      <td>7928000000</td>\n",
       "      <td>0.077816</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.315016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-31</th>\n",
       "      <td>21301000000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1129000000</td>\n",
       "      <td>-0.153614</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>0.053002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-30</th>\n",
       "      <td>25500000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1478000000</td>\n",
       "      <td>0.197127</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.057961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30</th>\n",
       "      <td>25182000000</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2167000000</td>\n",
       "      <td>-0.012471</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.086054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>25707000000</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2314000000</td>\n",
       "      <td>0.020848</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.090014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-03-31</th>\n",
       "      <td>19335000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>409000000</td>\n",
       "      <td>-0.247870</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.021153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>22496000000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1134000000</td>\n",
       "      <td>0.163486</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.050409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-30</th>\n",
       "      <td>28095000000</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1853000000</td>\n",
       "      <td>0.248889</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.065955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-31</th>\n",
       "      <td>24901000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1076000000</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge Everything into One Master Dataset\n",
    "\n",
    "All external data is aligned to TSLA trading days and forward-filled where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.553999Z",
     "iopub.status.busy": "2026-02-17T16:03:02.553934Z",
     "iopub.status.idle": "2026-02-17T16:03:02.627515Z",
     "shell.execute_reply": "2026-02-17T16:03:02.627104Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:08:06.732622Z",
     "start_time": "2026-02-19T15:08:06.644593Z"
    }
   },
   "source": [
    "from src.helpers import align_to_trading_days\n",
    "\n",
    "master = df_ta.copy()\n",
    "trading_dates = master.index\n",
    "\n",
    "# --- Merge tweets ---\n",
    "if TWEETS_PATH.exists():\n",
    "    tw = align_to_trading_days(tweets_daily, trading_dates)\n",
    "    # Fill days with no tweets as 0\n",
    "    for c in tw.columns:\n",
    "        tw[c] = tw[c].fillna(0)\n",
    "    master = master.join(tw, how='left')\n",
    "\n",
    "# --- Merge Google Trends (weekly → forward-fill to daily) ---\n",
    "if gtrends is not None:\n",
    "    gt = align_to_trading_days(gtrends, trading_dates)\n",
    "    master = master.join(gt, how='left')\n",
    "\n",
    "# --- Merge fundamentals (quarterly → forward-fill) ---\n",
    "if not fundamentals.empty:\n",
    "    fund = align_to_trading_days(fundamentals, trading_dates)\n",
    "    master = master.join(fund, how='left')\n",
    "\n",
    "print(f\"Master dataset shape: {master.shape}\")\n",
    "print(f\"Columns ({len(master.columns)}): {list(master.columns)}\")\n",
    "master.to_csv(DATA_PROCESSED / 'master_dataset.csv')\n",
    "print(f\"Saved to {DATA_PROCESSED / 'master_dataset.csv'}\")\n",
    "master.tail()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset shape: (3935, 52)\n",
      "Columns (52): ['Open', 'High', 'Low', 'Close', 'Volume', 'target', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'EMA_12', 'EMA_26', 'RSI_14', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'BBL_20_2.0_2.0', 'BBM_20_2.0_2.0', 'BBU_20_2.0_2.0', 'BBB_20_2.0_2.0', 'BBP_20_2.0_2.0', 'ATRr_14', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHh_14_3_3', 'OBV', 'volatility_20', 'tweet_count', 'tweet_bull_count', 'tweet_bear_count', 'tweet_word_score', 'tesla_tweet_count', 'has_tesla_tweet', 'gtrend_tesla', 'gtrend_risk_tesla_recall', 'gtrend_risk_tesla_crash', 'gtrend_risk_tesla_lawsuit', 'gtrend_risk_tesla_investigation', 'gtrend_investor_buy_tesla_stock', 'gtrend_investor_sell_tesla_stock', 'gtrend_investor_tsla_earnings', 'gtrend_investor_tesla_stock_price', 'gtrend_product_tesla_fsd', 'gtrend_product_tesla_robotaxi', 'gtrend_product_cybertruck_delivery', 'gtrend_product_tesla_model_2', 'quarterly_revenue', 'eps_diluted', 'net_income', 'revenue_growth_qoq', 'eps_growth_qoq', 'profit_margin']\n",
      "Saved to /Users/matheomenges/Desktop/tsla-direction-predictor/data/processed/master_dataset.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  Open        High         Low       Close    Volume  target  \\\n",
       "Date                                                                           \n",
       "2026-02-12  430.299988  436.230011  414.000000  417.070007  61933400       1   \n",
       "2026-02-13  414.309998  424.059998  410.880005  417.440002  51434100       0   \n",
       "2026-02-17  412.359985  413.720001  400.510010  410.630005  59678800       1   \n",
       "2026-02-18  411.109985  416.899994  409.579987  411.320007  45831600       0   \n",
       "2026-02-19  407.333496  410.299988  404.109985  409.349915   9269167       0   \n",
       "\n",
       "                 SMA_5      SMA_10      SMA_20      SMA_50  ...  \\\n",
       "Date                                                        ...   \n",
       "2026-02-12  419.795996  417.637997  425.783998  444.184200  ...   \n",
       "2026-02-13  421.062000  416.340997  424.727498  443.948201  ...   \n",
       "2026-02-17  419.723999  415.222998  423.383998  443.226001  ...   \n",
       "2026-02-18  416.946002  414.159000  422.987498  442.361801  ...   \n",
       "2026-02-19  413.161987  414.492990  421.882994  441.448799  ...   \n",
       "\n",
       "            gtrend_product_tesla_fsd  gtrend_product_tesla_robotaxi  \\\n",
       "Date                                                                  \n",
       "2026-02-12                      16.0                            2.0   \n",
       "2026-02-13                      16.0                            2.0   \n",
       "2026-02-17                      17.0                            3.0   \n",
       "2026-02-18                      17.0                            3.0   \n",
       "2026-02-19                      17.0                            3.0   \n",
       "\n",
       "            gtrend_product_cybertruck_delivery  gtrend_product_tesla_model_2  \\\n",
       "Date                                                                           \n",
       "2026-02-12                                 0.0                           8.0   \n",
       "2026-02-13                                 0.0                           8.0   \n",
       "2026-02-17                                 0.0                           8.0   \n",
       "2026-02-18                                 0.0                           8.0   \n",
       "2026-02-19                                 0.0                           8.0   \n",
       "\n",
       "            quarterly_revenue  eps_diluted    net_income  revenue_growth_qoq  \\\n",
       "Date                                                                           \n",
       "2026-02-12       2.490100e+10         0.24  1.076000e+09           -0.113686   \n",
       "2026-02-13       2.490100e+10         0.24  1.076000e+09           -0.113686   \n",
       "2026-02-17       2.490100e+10         0.24  1.076000e+09           -0.113686   \n",
       "2026-02-18       2.490100e+10         0.24  1.076000e+09           -0.113686   \n",
       "2026-02-19       2.490100e+10         0.24  1.076000e+09           -0.113686   \n",
       "\n",
       "            eps_growth_qoq  profit_margin  \n",
       "Date                                       \n",
       "2026-02-12           -0.15       0.043211  \n",
       "2026-02-13           -0.15       0.043211  \n",
       "2026-02-17           -0.15       0.043211  \n",
       "2026-02-18           -0.15       0.043211  \n",
       "2026-02-19           -0.15       0.043211  \n",
       "\n",
       "[5 rows x 52 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>target</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>...</th>\n",
       "      <th>gtrend_product_tesla_fsd</th>\n",
       "      <th>gtrend_product_tesla_robotaxi</th>\n",
       "      <th>gtrend_product_cybertruck_delivery</th>\n",
       "      <th>gtrend_product_tesla_model_2</th>\n",
       "      <th>quarterly_revenue</th>\n",
       "      <th>eps_diluted</th>\n",
       "      <th>net_income</th>\n",
       "      <th>revenue_growth_qoq</th>\n",
       "      <th>eps_growth_qoq</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-02-12</th>\n",
       "      <td>430.299988</td>\n",
       "      <td>436.230011</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>417.070007</td>\n",
       "      <td>61933400</td>\n",
       "      <td>1</td>\n",
       "      <td>419.795996</td>\n",
       "      <td>417.637997</td>\n",
       "      <td>425.783998</td>\n",
       "      <td>444.184200</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.490100e+10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-13</th>\n",
       "      <td>414.309998</td>\n",
       "      <td>424.059998</td>\n",
       "      <td>410.880005</td>\n",
       "      <td>417.440002</td>\n",
       "      <td>51434100</td>\n",
       "      <td>0</td>\n",
       "      <td>421.062000</td>\n",
       "      <td>416.340997</td>\n",
       "      <td>424.727498</td>\n",
       "      <td>443.948201</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.490100e+10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-17</th>\n",
       "      <td>412.359985</td>\n",
       "      <td>413.720001</td>\n",
       "      <td>400.510010</td>\n",
       "      <td>410.630005</td>\n",
       "      <td>59678800</td>\n",
       "      <td>1</td>\n",
       "      <td>419.723999</td>\n",
       "      <td>415.222998</td>\n",
       "      <td>423.383998</td>\n",
       "      <td>443.226001</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.490100e+10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-18</th>\n",
       "      <td>411.109985</td>\n",
       "      <td>416.899994</td>\n",
       "      <td>409.579987</td>\n",
       "      <td>411.320007</td>\n",
       "      <td>45831600</td>\n",
       "      <td>0</td>\n",
       "      <td>416.946002</td>\n",
       "      <td>414.159000</td>\n",
       "      <td>422.987498</td>\n",
       "      <td>442.361801</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.490100e+10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-02-19</th>\n",
       "      <td>407.333496</td>\n",
       "      <td>410.299988</td>\n",
       "      <td>404.109985</td>\n",
       "      <td>409.349915</td>\n",
       "      <td>9269167</td>\n",
       "      <td>0</td>\n",
       "      <td>413.161987</td>\n",
       "      <td>414.492990</td>\n",
       "      <td>421.882994</td>\n",
       "      <td>441.448799</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.490100e+10</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.076000e+09</td>\n",
       "      <td>-0.113686</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.043211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.628461Z",
     "iopub.status.busy": "2026-02-17T16:03:02.628400Z",
     "iopub.status.idle": "2026-02-17T16:03:02.632630Z",
     "shell.execute_reply": "2026-02-17T16:03:02.632326Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:08:09.493992Z",
     "start_time": "2026-02-19T15:08:09.485576Z"
    }
   },
   "source": [
    "from src.helpers import missing_report\n",
    "missing_report(master)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                    missing    pct\n",
       "gtrend_product_tesla_model_2           1388  35.27\n",
       "gtrend_risk_tesla_lawsuit              1388  35.27\n",
       "gtrend_risk_tesla_recall               1388  35.27\n",
       "gtrend_tesla                           1388  35.27\n",
       "gtrend_risk_tesla_investigation        1388  35.27\n",
       "gtrend_investor_buy_tesla_stock        1388  35.27\n",
       "gtrend_investor_sell_tesla_stock       1388  35.27\n",
       "gtrend_investor_tsla_earnings          1388  35.27\n",
       "gtrend_investor_tesla_stock_price      1388  35.27\n",
       "gtrend_product_tesla_fsd               1388  35.27\n",
       "gtrend_product_tesla_robotaxi          1388  35.27\n",
       "gtrend_product_cybertruck_delivery     1388  35.27\n",
       "gtrend_risk_tesla_crash                1388  35.27\n",
       "revenue_growth_qoq                      507  12.88\n",
       "eps_growth_qoq                          507  12.88\n",
       "quarterly_revenue                       444  11.28\n",
       "eps_diluted                             444  11.28\n",
       "net_income                              444  11.28\n",
       "profit_margin                           444  11.28\n",
       "SMA_50                                   49   1.25\n",
       "MACDs_12_26_9                            33   0.84\n",
       "MACDh_12_26_9                            33   0.84\n",
       "MACD_12_26_9                             25   0.64\n",
       "EMA_26                                   25   0.64\n",
       "volatility_20                            20   0.51\n",
       "BBP_20_2.0_2.0                           19   0.48\n",
       "BBB_20_2.0_2.0                           19   0.48\n",
       "BBU_20_2.0_2.0                           19   0.48\n",
       "BBM_20_2.0_2.0                           19   0.48\n",
       "BBL_20_2.0_2.0                           19   0.48\n",
       "SMA_20                                   19   0.48\n",
       "STOCHh_14_3_3                            17   0.43\n",
       "STOCHd_14_3_3                            17   0.43\n",
       "STOCHk_14_3_3                            15   0.38\n",
       "ATRr_14                                  13   0.33\n",
       "EMA_12                                   11   0.28\n",
       "SMA_10                                    9   0.23\n",
       "SMA_5                                     4   0.10\n",
       "OBV                                       1   0.03\n",
       "RSI_14                                    1   0.03"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gtrend_product_tesla_model_2</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_risk_tesla_lawsuit</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_risk_tesla_recall</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_tesla</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_risk_tesla_investigation</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_investor_buy_tesla_stock</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_investor_sell_tesla_stock</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_investor_tsla_earnings</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_investor_tesla_stock_price</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_product_tesla_fsd</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_product_tesla_robotaxi</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_product_cybertruck_delivery</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtrend_risk_tesla_crash</th>\n",
       "      <td>1388</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenue_growth_qoq</th>\n",
       "      <td>507</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eps_growth_qoq</th>\n",
       "      <td>507</td>\n",
       "      <td>12.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quarterly_revenue</th>\n",
       "      <td>444</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eps_diluted</th>\n",
       "      <td>444</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>net_income</th>\n",
       "      <td>444</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit_margin</th>\n",
       "      <td>444</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMA_50</th>\n",
       "      <td>49</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <td>33</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <td>33</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMA_26</th>\n",
       "      <td>25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatility_20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBP_20_2.0_2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBB_20_2.0_2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBU_20_2.0_2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBM_20_2.0_2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBL_20_2.0_2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMA_20</th>\n",
       "      <td>19</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHh_14_3_3</th>\n",
       "      <td>17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHd_14_3_3</th>\n",
       "      <td>17</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOCHk_14_3_3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATRr_14</th>\n",
       "      <td>13</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMA_12</th>\n",
       "      <td>11</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMA_10</th>\n",
       "      <td>9</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMA_5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBV</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI_14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-17T16:03:02.633666Z",
     "iopub.status.busy": "2026-02-17T16:03:02.633614Z",
     "iopub.status.idle": "2026-02-17T16:03:02.638661Z",
     "shell.execute_reply": "2026-02-17T16:03:02.638293Z"
    },
    "ExecuteTime": {
     "end_time": "2026-02-19T15:08:18.203692Z",
     "start_time": "2026-02-19T15:08:18.194725Z"
    }
   },
   "source": "# ── Data quality overview ──\nprint(\"=\" * 60)\nprint(\"DATA QUALITY SUMMARY\")\nprint(\"=\" * 60)\n\nprint(f\"\\nMASTER DATASET: {master.shape[0]} trading days x {master.shape[1]} columns\")\nprint(f\"   Date range: {master.index.min().date()} -> {master.index.max().date()}\")\nprint(f\"   Target: {master['target'].value_counts()[1]} up days ({master['target'].mean():.1%}), \"\n      f\"{master['target'].value_counts()[0]} down days\")\n\nprint(f\"\\nOHLCV: complete ({tsla.isna().sum().sum()} missing values)\")\nprint(f\"   Volume range: {tsla['Volume'].min():,.0f} -- {tsla['Volume'].max():,.0f}\")\n\nprint(f\"\\nTECHNICAL INDICATORS: {len([c for c in df_ta.columns if c not in tsla.columns])} features\")\nprint(f\"   Warmup NaN rows: ~{df_ta[['SMA_50']].isna().sum().values[0]} (first {df_ta[['SMA_50']].isna().sum().values[0]} days)\")\n\nif TWEETS_PATH.exists():\n    tesla_tweet_days = tweets_daily['has_tesla_tweet'].sum()\n    print(f\"\\nTWEETS: {len(tweets_raw)} raw -> {len(tweets_daily)} daily aggregates\")\n    print(f\"   Date range: {tweets_daily.index.min().date()} -> {tweets_daily.index.max().date()}\")\n    print(f\"   Days with Tesla-related keywords: {tesla_tweet_days} ({tesla_tweet_days/len(tweets_daily):.1%})\")\n    print(f\"   Note: Sparse before 2017 -- most tweets are general, not Tesla-specific\")\n\nif gtrends is not None:\n    gt_cats = {}\n    for c in gtrends.columns:\n        parts = c.replace('gtrend_', '').split('_', 1)\n        cat = parts[0] if len(parts) > 1 else 'brand'\n        gt_cats.setdefault(cat, []).append(c)\n    print(f\"\\nGOOGLE TRENDS: {len(gtrends)} weekly data points ({gtrends.index.min().date()} -> {gtrends.index.max().date()})\")\n    print(f\"   {len(gtrends.columns)} signals across {len(gt_cats)} categories: {list(gt_cats.keys())}\")\n    print(f\"   Granularity: weekly (forward-filled to daily)\")\n    print(f\"   Note: Missing for 2010-2015 (pre-collection range)\")\n\nif not fundamentals.empty:\n    print(f\"\\nFUNDAMENTALS: {len(fundamentals)} quarters\")\n    print(f\"   Date range: {fundamentals.index.min().date()} -> {fundamentals.index.max().date()}\")\n    print(f\"   Columns: {list(fundamentals.columns)}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"RECOMMENDATION FOR MODELING:\")\nprint(\"=\" * 60)\nprint(\"* Strong features: OHLCV + all technical indicators (complete)\")\nprint(\"* Moderate: Tweet sentiment (useful from ~2017 onward)\")\nprint(\"* Moderate: Google Trends (weekly categorized -- risk/investor/product signals)\")\nprint(\"* Moderate: Fundamentals (quarterly, forward-filled)\")\nprint(\"* Consider training on 2016+ data for best feature coverage\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY SUMMARY\n",
      "============================================================\n",
      "\n",
      "MASTER DATASET: 3935 trading days x 52 columns\n",
      "   Date range: 2010-06-29 -> 2026-02-19\n",
      "   Target: 2029 up days (51.6%), 1906 down days\n",
      "\n",
      "OHLCV: complete (0 missing values)\n",
      "   Volume range: 1,777,500 -- 914,082,000\n",
      "\n",
      "TECHNICAL INDICATORS: 21 features\n",
      "   Warmup NaN rows: ~49 (first 49 days)\n",
      "\n",
      "TWEETS: 55099 raw -> 2911 daily aggregates\n",
      "   Date range: 2010-06-04 -> 2025-04-13\n",
      "   Days with Tesla-related keywords: 950 (32.6%)\n",
      "   Note: Sparse before 2017 -- most tweets are general, not Tesla-specific\n",
      "\n",
      "GOOGLE TRENDS: 328 weekly data points (2016-01-01 -> 2026-02-15)\n",
      "   13 signals across 4 categories: ['brand', 'risk', 'investor', 'product']\n",
      "   Granularity: weekly (forward-filled to daily)\n",
      "   Note: Missing for 2010-2015 (pre-collection range)\n",
      "\n",
      "FUNDAMENTALS: 56 quarters\n",
      "   Date range: 2012-03-31 -> 2025-12-31\n",
      "   Columns: ['quarterly_revenue', 'eps_diluted', 'net_income', 'revenue_growth_qoq', 'eps_growth_qoq', 'profit_margin']\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATION FOR MODELING:\n",
      "============================================================\n",
      "* Strong features: OHLCV + all technical indicators (complete)\n",
      "* Moderate: Tweet sentiment (useful from ~2017 onward)\n",
      "* Moderate: Google Trends (weekly categorized -- risk/investor/product signals)\n",
      "* Moderate: Fundamentals (quarterly, forward-filled)\n",
      "* Consider training on 2016+ data for best feature coverage\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
